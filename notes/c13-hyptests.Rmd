---
title: 'chapter 13 Testing Significance'
output:
  tufte::tufte_html:
    tufte_features: ['fonts','background','italics']
    css: '../mytufte.css'
    toc: true
    toc_depth: 2
  tufte::tufte_handout:
    citation_package: natbib
    latex_engine: xelatex
  tufte::tufte_book:
    citation_package: natbib
link-citations: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = FALSE)
library(tidyverse)
library(ggplot2)
library(knitr)
library(kableExtra)
library(extraDistr)
library(gridExtra)
library(latex2exp)
library(moments)
library(bookdown)
library(rsconnect)
```

```{r, include=FALSE}
paygap <- read.csv('./data/gender-paygap-2019.csv')
paygap <- paygap %>%
  mutate(EmployerSize = factor(EmployerSize, levels = c('0-249','250-499','500-999','1000-4999','5000-19999','20000+')))
nycheat <- read.csv('./data/nyc-heatwave.csv')
```

\newcommand{\E}{\text{E}}
\newcommand{\Var}{\text{Var}}
\newcommand{\SD}{\text{SD}}
\newcommand{\SE}{\text{SE}}
\newcommand{\Cov}{\text{Cov}}
\newcommand{\Cor}{\text{Cor}}
\renewcommand{\P}{\text{P}}
\newcommand{\pd}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\sumin}{\sum_i^n}
\newcommand{\Bias}{\text{Bias}}

---

# Hypothesis Tests

A statistical hypothesis is an assumption about one or more population parameters. The assumption may or may not be true, and one of our goals in statistical inference is using data to determine whether we should accept or reject a given hypothesis.  

**Hypothesis testing** provides a framework for accepting or rejecting a hypothesis, by comparing two competing models for what a population really looks like. To conduct a hypothesis test, we first define a proposed/pre-existing model for the population parameter(s)---this is called the **null hypothesis**. Generally it can be based anything---the results of a previous experiment, or even just a hunch we might have about the population.  

We then compare the null hypothesis to a competing model for the population parameters, usually in the form of a (new) sample of data. If the competing model yields vastly different results results to those predicted by the null model (i.e. if the new data is an *unlikely realization* of the null), we have grounds to reject the null. The **alternative hypothesis** describes the scenario under which the null is not true.  

- **the null hypothesis**, $H_0$: a proposed/pre-existing model for the true population parameter(s)
- **the alternative hypothesis**, $H_1$: the scenario under which the null is not true  

Note the alternative hypothesis is always stated as a *negation* of the null. Hypothesis tests give us a framework for *disproving* a given model, but not for uniquely specifying one.  

\ 

## A simple example

In the pay gap data, the variable `DiffMeanHourlyPercent`^[i.e. the difference in mean hourly wages between females and males.] has a sample mean of $\bar X =$ `r toString(round(mean(paygap$DiffMeanHourlyPercent),3))`. If we assumed this sample is representative, we could use it to define a null hypothesis, that the true mean hourly wage gap is 12.356\%. Naturally, we're now interested in determining whether this hypothesis is really true or not. Let's imagine that the following year we collect a new sample of data, which for the same variable yielded a sample mean $\bar X = 9.42$. We can now test whether our initial hypothesis should be accepted or rejected on the basis of this new evidence. The null and alternative hypotheses for this test are:

$$H_0: \mu = 12.356$$
$$H_1: \mu \neq 12.356$$

The most common method used for determining whether to accept/reject a null is by quantifying the *likelihood* of getting the observed value, if the null hypothesis were true. If the likelihood is sufficiently low, this implies there's a good chance the null hypothesis may not be true.  

The **significance level** ($\alpha$) of a test is the probability threshold below which we decide to reject the null. Conventionally a significance level of $\alpha = 0.05$ is used---i.e. we reject the null if the observed value lies in the most extreme 5\% of values under the null distribution. Sometimes a significance level of $\alpha = 0.01$ is also used.    

The **rejection region** of a test is the range of values for which which we reject the null. The size of the rejection region is determined by the significance level you decide on. Below are two plots of the distribution of $\bar X$ under the null hypothesis, with rejection regions for $\alpha = 0.05$ and $\alpha = 0.01$ shown: 


```{r, echo=FALSE, warning=FALSE, fig.width = 10, fig.height=4}
Xbar = mean(paygap$DiffMeanHourlyPercent)   #sample mean
s = sd(paygap$DiffMeanHourlyPercent)   #sample s.d.
n = nrow(paygap)   #sample size
SE = s / sqrt(n)   #standard error

x = seq(-4, 4, length = 1000) * SE + Xbar
y = dnorm(x, Xbar, SE)

df = data.frame(x = x, y = y)

breaks = round(seq(Xbar-4*SE, Xbar+4*SE, SE),3)

alpha5 = 0.05
alpha1 = 0.01

Z_5 = qnorm(1-alpha5/2)
Z_1 = qnorm(1-alpha1/2)

plot1 = ggplot(data = df, mapping = aes(x = x, y = y)) +
  geom_line() +
  scale_x_continuous(breaks = breaks,
                     limits = c(Xbar-4*SE, Xbar+4*SE)) +
  ylab('probability') + xlab(TeX('$\\bar{X}$')) +
  ggtitle(TeX('Rejection region for $\\alpha = 0.05$')) +
  geom_area(aes(x = ifelse(x < Xbar - Z_5*SE, x, 0)), fill='violetred', alpha=0.4) +
  geom_area(aes(x = ifelse(x > Xbar + Z_5*SE, x, 0)), fill='violetred', alpha=0.4) +
  geom_segment(x = Xbar - Z_5*SE, xend = Xbar - Z_5*SE, y = 0, yend = 0.1, color = 'violetred', linetype = 'dotted') + 
  geom_segment(x = Xbar + Z_5*SE, xend = Xbar + Z_5*SE, y = 0, yend = 0.1, color = 'violetred', linetype = 'dotted') +
  geom_text(label = 'p = 0.025', x = 8.8, y = -0.005, size = 2.5, color = 'violetred') +
  geom_text(label = 'p = 0.025', x = 15.7, y = -0.005, size = 2.5, color = 'violetred') +
  geom_text(label = 'critical \n value', x = Xbar - Z_5*SE, y = 0.12, size = 3, color = 'violetred') +
  geom_text(label = 'critical \n value', x = Xbar + Z_5*SE, y = 0.12, size = 3, color = 'violetred') +
  theme_bw()

plot2 = ggplot(data = df, mapping = aes(x = x, y = y)) +
  geom_line() +
  scale_x_continuous(breaks = breaks,
                     limits = c(Xbar-4*SE, Xbar+4*SE)) +
  ylab('probability') + xlab(TeX('$\\bar{X}$')) +
  ggtitle(TeX('Rejection region for $\\alpha = 0.01$')) +
  geom_area(aes(x = ifelse(x < Xbar - Z_1*SE, x, 0)), fill='violetred', alpha=0.4) +
  geom_area(aes(x = ifelse(x > Xbar + Z_1*SE, x, 0)), fill='violetred', alpha=0.4) +
  geom_segment(x = Xbar - Z_1*SE, xend = Xbar - Z_1*SE, y = 0, yend = 0.1, color = 'violetred', linetype = 'dotted') + 
  geom_segment(x = Xbar + Z_1*SE, xend = Xbar + Z_1*SE, y = 0, yend = 0.1, color = 'violetred', linetype = 'dotted') +
  geom_text(label = 'p = 0.005', x = 8.4, y = -0.005, size = 2.5, color = 'violetred') +
  geom_text(label = 'p = 0.005', x = 16.1, y = -0.005, size = 2.5, color = 'violetred') +
  geom_text(label = 'critical \n value', x = Xbar - Z_1*SE, y = 0.12, size = 3, color = 'violetred') +
  geom_text(label = 'critical \n value', x = Xbar + Z_1*SE, y = 0.12, size = 3, color = 'violetred') +
  theme_bw()

grid.arrange(plot1, plot2, ncol = 2)
  
  
  
  # geom_text(label = TeX('$-3 \\frac{ s }{ \\sqrt{n} }$'), x = Xbar-3*SE, y = 0.025, size=3, color = 'darkgrey') +
  # geom_text(label = TeX('$-2 \\frac{ s }{ \\sqrt{n} }$'), x = Xbar-2*SE, y = 0.025, size=3, color = 'darkgrey') +
  # geom_text(label = TeX('$-1 \\frac{ s }{ \\sqrt{n} }$'), x = Xbar-1*SE, y = 0.025, size=3, color = 'darkgrey') +
  # geom_text(label = TeX('$\\bar{X}$'), x = Xbar, y = 0.025, size=3, color = 'darkgrey') +
  # geom_text(label = TeX('$+1 \\frac{ s }{ \\sqrt{n} }$'), x = Xbar+1*SE, y = 0.025, size=3, color = 'darkgrey') +
  # geom_text(label = TeX('$+2 \\frac{ s }{ \\sqrt{n} }$'), x = Xbar+2*SE, y = 0.025, size=3, color = 'darkgrey') +
  # geom_text(label = TeX('$+3 \\frac{ s }{ \\sqrt{n} }$'), x = Xbar+3*SE, y = 0.025, size=3, color = 'darkgrey') +
  # theme_bw()
```

The **critical values** are the bounds of the rejection region. If $\alpha = 0.05$, the critical values are the 2.5th and 97.5th percentiles of the distribution. You can calculate these using `qt()`, or you can simply compute a 95\% confidence interval for the mean:

```{r, echo=FALSE}
confidence_interval <- function(data, conflevel) {
  xbar <- mean(data)          # sample mean 
  SE <- sd(data) / sqrt(n)    # standard error
  n <- length(data)           # sample size 
  alpha <- 1 - conflevel      # alpha
  
  lb <- xbar + qt(alpha/2, df = n-1) * SE    # lower bound
  ub <- xbar + qt(1-alpha/2, df = n-1) * SE  # upper bound
  
  cat(paste(c('sample mean =', round(xbar,3), '\n', 
              conflevel*100, '% confidence interval:', '\n', 
              'lower bound =', round(lb,3), '\n', 
              'upper bound =', round(ub,3))))
}
```

```{r}
confidence_interval(paygap$DiffMeanHourlyPercent, 0.95)
```

The rejection region is thus $\bar X < 9.799$ \& $\bar X > 14.913$.  

A test is **statistically significant** if the observed value falls in the rejection region. In this example, where the observed value is $\bar X = 9.42$ and $\alpha = 0.05$:

```{r, echo=FALSE, warning=FALSE}
ggplot(data = df, mapping = aes(x = x, y = y)) +
  geom_line() +
  scale_x_continuous(breaks = breaks,
                     limits = c(Xbar-4*SE, Xbar+4*SE)) +
  ylab('probability') + xlab(TeX('$\\bar{X}$')) +
  ggtitle(TeX('Significance test with $\\alpha = 0.05$')) +
  geom_area(aes(x = ifelse(x < Xbar - Z_5*SE, x, 0)), fill='violetred', alpha=0.4) +
  geom_area(aes(x = ifelse(x > Xbar + Z_5*SE, x, 0)), fill='violetred', alpha=0.4) +
  geom_segment(x = Xbar - Z_5*SE, xend = Xbar - Z_5*SE, y = 0, yend = 0.1, color = 'violetred', linetype = 'dotted') + 
  geom_segment(x = Xbar + Z_5*SE, xend = Xbar + Z_5*SE, y = 0, yend = 0.1, color = 'violetred', linetype = 'dotted') +
  geom_segment(x = 9.42, xend = 9.42, y = 0, yend = 0.25, color = 'black', linetype = 'dotted') + 
  geom_text(label = 'observed \n value \n = 9.42', x = 9.42, y = 0.27, size = 3, color = 'black') +
  geom_text(label = 'critical \n value \n = 9.80', x = Xbar - Z_5*SE, y = 0.13, size = 3, color = 'violetred') +
  geom_text(label = 'critical \n value \n = 14.91', x = Xbar + Z_5*SE, y = 0.13, size = 3, color = 'violetred') +
  theme_bw()
```

Since in this test, the observed value is in the rejection region, there are grounds to reject the null hypothesis, and you can conclude that the true population mean $\mu \neq 12.356$.  

Note, if you had used a significance level of $\alpha = 0.01$ to conduct the test, you would not have reached this conclusion: 

```{r, echo=FALSE, warning=FALSE}
ggplot(data = df, mapping = aes(x = x, y = y)) +
  geom_line() +
  scale_x_continuous(breaks = breaks,
                     limits = c(Xbar-4*SE, Xbar+4*SE)) +
  ylab('probability') + xlab(TeX('$\\bar{X}$')) +
  ggtitle(TeX('Significance test with $\\alpha = 0.01$')) +
  geom_area(aes(x = ifelse(x < Xbar - Z_1*SE, x, 0)), fill='violetred', alpha=0.4) +
  geom_area(aes(x = ifelse(x > Xbar + Z_1*SE, x, 0)), fill='violetred', alpha=0.4) +
  geom_segment(x = Xbar - Z_1*SE, xend = Xbar - Z_1*SE, y = 0, yend = 0.1, color = 'violetred', linetype = 'dotted') + 
  geom_segment(x = Xbar + Z_1*SE, xend = Xbar + Z_1*SE, y = 0, yend = 0.1, color = 'violetred', linetype = 'dotted') +
  geom_segment(x = 9.42, xend = 9.42, y = 0, yend = 0.25, color = 'black', linetype = 'dotted') + 
  geom_text(label = 'observed \n value \n = 9.42', x = 9.42, y = 0.27, size = 3, color = 'black') +
  geom_text(label = 'critical \n value', x = Xbar - Z_1*SE, y = 0.12, size = 3, color = 'violetred') +
  geom_text(label = 'critical \n value', x = Xbar + Z_1*SE, y = 0.12, size = 3, color = 'violetred') +
  theme_bw()
```

I.e. with a significance level of $\alpha = 0.01$, you would **fail to reject** the null.  

\ 

## The p-value of a test

Another way to conduct a hypothesis test is by looking at $p$-values.  

The **p-value** of a test is the probability of getting a result at least as extreme as the observed value, under the null hypothesis.  

This is a cumbersone definition, but it is easy to visualize. In the above example, the observed value is $\bar X = 9.42$. The probability of getting a value *at least as extreme* as $\bar X = 9.42$ is the following region:

```{r, echo=FALSE, warning=FALSE}
p = pnorm(9.42, mean = Xbar, sd = SE)
Z = -qnorm(p)

ggplot(data = df, mapping = aes(x = x, y = y)) +
  geom_line() +
  scale_x_continuous(breaks = breaks,
                     limits = c(Xbar-4*SE, Xbar+4*SE)) +
  ylab('probability') + xlab(TeX('$\\bar{X}$')) +
  ggtitle(TeX('The p-value')) +
  geom_area(aes(x = ifelse(x < Xbar - Z*SE, x, 0)), fill='violetred', alpha=0.4) +
  geom_area(aes(x = ifelse(x > Xbar + Z*SE, x, 0)), fill='violetred', alpha=0.4) +
  geom_segment(x = 9.42, xend = 9.42, y = 0, yend = 0.25, color = 'black', linetype = 'dotted') + 
  geom_text(label = 'observed \n value \n = 9.42', x = 9.42, y = 0.27, size = 3, color = 'black') +
  geom_text(label = 'p = 0.0116', x = 8.8, y = -0.005, size = 3, color = 'violetred') + 
  geom_text(label = 'p = 0.0116', x = 15.7, y = -0.005, size = 3, color = 'violetred') + 
  theme_bw()
```

Each region has a probability of 0.0116, which means the total probability of getting a value at least as extreme as the observed value is 
0.0233. The $p$-value of this test is thus 0.0233. The $p$-value is statistically significant if it is smaller than the significance level of the test. If $\alpha = 0.05$, then the result is statistically significant, and you can reject the null hypothesis. But if you used a significance level of $\alpha = 0.01$, the converse is true.  

\ 

## A workflow 

When conducting a hypothesis test, you should follow these steps:

- state the null and alternative hypotheses. The null is based on the data (or hunch) you already have; it is a proposed model for one or more population parameters(s). The alternative hypothesis describes the scenario where the null is not true.   
- choose a significance level, $\alpha$, for the test -- a probability threshold below which you will reject the null. Common levels are $\alpha = 0.05$ and $\alpha = 0.01$.  

Either: 

- determine the rejection region or critical region -- a range for the observed value that would cause you to reject the null. The bounds of the rejection region are determined by the significance level.  
- state the observed value -- the sample statistic in question from the new data 
- determine whether to reject the null hypothesis based on whether the observed value is in the rejection region or not

Or: 

- calculate the $p$-value -- the probability of getting a value at least as extreme as the observed value
- reject the null if the $p$-value is smaller than the significance level




\ 

--- 

# Errors and Power

Of course, the result of a hypothesis test does not necessarily lead you to the correct result. If a hypothesis test yields a rejection, this is only *evidence* to suggest the null *might* be false, but not definitively so. There is always a chance the observed value is aberrant and the null is actually correct. Thus it is useful to quantify the error of a test.  

A **Type I Error** is the probability of rejecting the null, when the null is true. The Type I Error is simply the significance level of a test.  

A **Type II Error** is the probability of failing to reject the null, when the null is false.  

The **Power** of a test is the probability of correctly rejecting a false null (the complement of Type II Error, i.e. Power = 1 - T2E).  

Usually the foremost goal of a significance test is to ensure the probability of Type I Error is low.  

The second goal is to choose the test with the lowest probability of Type II Error (i.e. choose the most powerful test). 



\ 

--- 

# Examples of Hypothesis Tests

\ 

## Difference of sample means

A score ages ago was 290. The score now is 285. Is this a statistically significant change, or is it just chance variation? 

You can use the z-test. Recall the z-statistic is calculated as follows:

$$Z = \frac{\bar X - \mu}{SE}$$

where $SE = \frac{s}{\sqrt n}$, where $s$ is the sample standard deviation. Once you compute a test statistic, you can calculate its probability, which will give you a result.  

The easiest way to answer this problem is to think of the two samples as two independent RVs. You can then create a new RV that is a linear combination of both. E.g. let X be the RV for the difference between the two samples, i.e. X = W - V. 

The expected value of X is: $E[X] = 0$ since the null is that there is no difference. The observed value is W-V=5. 

Recall the formula for linear combinations of Variance: $Var[W-V] = Var[W] + Var[V] = \frac{s_v^2}{n} + \frac{s_w^2}{n}$. Thus the standard error is:

$$SE = \sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}$$





